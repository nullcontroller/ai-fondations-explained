## 数学的・確率論的説明

## 結論

プロンプトを書きすぎると精度が下がる主因は、  
制約集合が過拘束（over-constrained）となり、  
モデルが全条件を同時に満たす確率が指数関数的に低下するためである。

---

## 1. モデルの基本構造

大規模言語モデル（LLM）は本質的に、

P(次のトークン | 文脈)

を最大化する確率モデルである。

生成全体は、

P(y | C)

すなわち「条件Cのもとで出力yが生成される確率」を最大化する問題になる。

---

## 2. プロンプトを制約集合として定義する

プロンプトを次のような制約集合とする。

C = {c1, c2, c3, ..., cn}

各 ci は、

- トーン指定
- 出力形式指定
- 禁止語指定
- 論理順序指定
- 文字数制限
- 数式要求
- 出典要求
- 特定視点指定

などの条件である。

モデルは

P(y | c1, c2, ..., cn)

を最大化する。

---

## 3. 制約満足確率の乗算効果

単純化のため、各制約を満たす確率を独立と仮定する。

P(全制約を満たす) ≈ Π P(ci)

仮に各制約を満たす確率が0.9とする。

- 制約5個 → 0.9^5 = 0.59
- 制約10個 → 0.9^10 = 0.35
- 制約20個 → 0.9^20 = 0.12

制約数が増えるほど、
全条件を同時に満たせる確率は指数関数的に低下する。

---

## 4. 実際にはさらに悪化する理由

制約は独立ではない。

- 長文化要求と簡潔性要求
- 厳密性と創造性
- 禁止語指定と具体性要求
- 出典明示と自由構成

これらは相互干渉する。

その結果、

- どれかの制約を緩める
- 無難な表現に収束する
- 具体性を削る
- 一部条件を暗黙的に無視する

という挙動が生じてしまい、逆に制度が下がる現象が発生する。

---

## 5. 情報理論的観点

条件情報量は

I(C) = -log P(C)

条件が増えるほど必要な情報量は増大する。

しかしモデルの出力空間は有限であり、
表現容量も有限である。

したがって、

- 情報の圧縮
- 平均化
- 抽象化

が起きる。

その結果、文章が「薄く」なる。

---

## 6. 局所最適化の問題

モデルは

argmax_y P(y | C)

を探索するが、

制約が多すぎると探索空間が狭まりすぎて、
局所最適解に収束する。

これは

- 汎用的で無難な出力
- 安全側に倒れた表現
- 曖昧なまとめ

として現れる。

---

## 7. なぜ壊れるのか

制約が多すぎる場合、

モデルは

「全条件を満たす解」ではなく、
「最も破綻が少ない妥協解」

を選ぶ。

そのため、

- 一部制約が守られない
- 論理が弱くなる
- 表現が過度に抽象化する

という現象が起きる。

---

## 8. 最適化の原則

プロンプト設計で重要なのは、

- 制約を最小集合にする
- 独立性を保つ
- 優先順位を明示する
- 階層化する

である。

制約数を減らすことが目的ではなく、
「必要十分集合」にすることが重要。

---

## まとめ

書きすぎのプロンプトが壊れる理由は、

1. 制約満足確率が指数関数的に低下する
2. 制約同士が干渉する
3. 情報圧縮が起きる
4. 局所最適に落ちる

ためである。

よって、

プロンプトは多いほど精度が上がるのではなく、
多いほど破綻リスクが増える。

最適解は「最小構造制約」である。