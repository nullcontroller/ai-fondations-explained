## だから「制御」が必要になる

### 結論

**ハルシネーションを防ぐために必要なのは、AIの能力向上ではなく、確率空間の制御である。**

---

## なぜ制御しないといけないのか

AIは本質的に、

- 正しさを判定しない  
- 事実かどうかを検証しない  
- 現実との整合性を確認しない  

代わりに、

**確率が高い候補を選ぶだけ**

という動作を行っている。

したがって、

- 制御がない  
- 境界がない  
- 禁止がない  
状態では、

**ハルシネーションは必然的に発生する**

---

## 制御とは何か（誤解を避けるための定義）

ここで言う「制御」とは、

- 出力を監視すること  
- 後から修正すること  
- 間違いを指摘すること  

ではない。

制御とは、

**AIが選択肢として持ってよい確率空間そのものを事前に制限すること**

である。

---

## 制御がない場合に起きること

制御が弱いと、確率空間には次が同時に存在する。

- 正確な事実
- 不完全な理解
- 一般論
- 推測
- 創作的補完

AIはこれらを区別しないため、

**最も“それらしい”が、最も“正しい”とは限らない回答**

が選ばれる。

これがハルシネーションである。

---

## 制御がある場合に起きること

制御が入ると、

- 推測は禁止される
- 不明回答が許可される
- 参照範囲が限定される
- 判断が人に委譲される

その結果、

- 候補数が減る
- 外れ値が消える
- 最大確率候補が安定する

数学的には、

**確率分布が整理され、誤選択が起きにくくなる**

---

## 制御は「賢くする」ためではない

重要な整理として、

**制御はAIを賢くするためのものではない。AIを“壊れにくくする”ためのものである。**

- 理解力が上がるわけではない
- 判断力が生まれるわけではない

単に、

**間違った候補を選べなくしているだけ**

---

## なぜQAチャットでは特に制御が重要か

QAチャットでは、

- 正解らしさが強く求められる
- 文脈的な説得力が重視される
- 利用者が内容を信じやすい

そのため、

**一度のハルシネーションが信頼性を大きく損なう**

制御なしのQAチャットは、

- 見た目は便利  
- 中身は不安定  

という、最も危険な状態になる。

---

## 制御の責任は誰にあるか

AI自身ではない。

**制御は設計者（人間）の責任である。**

- どこまで答えてよいか
- どこで止まるべきか
- 何を参照してよいか

これらを決めない限り、

> **AIは常に  
> ハルシネーションを起こし得る存在**

であり続ける。

---

## 一文でまとめる

**ハルシネーションが起きるから制御するのではない。制御しない限り、ハルシネーションは必ず起きる。**

---